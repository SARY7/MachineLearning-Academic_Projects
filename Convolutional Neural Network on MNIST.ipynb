{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"q2_1.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KeUOOMqFhlPx","colab_type":"code","colab":{}},"source":["import numpy as np\n","from keras.models import Model\n","from keras import layers\n","import keras\n","from keras.datasets import fashion_mnist\n","from keras.utils import np_utils\n","\n","def plot_history(net_history):\n","    history = net_history.history\n","    import matplotlib.pyplot as plt\n","    losses = history['loss']\n","    val_losses = history['val_loss']\n","    accuracies = history['acc']\n","    val_accuracies = history['val_acc']\n","    \n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.plot(losses)\n","    plt.plot(val_losses)\n","    plt.legend(['train_loss', 'val_loss'])\n","    \n","    plt.figure()\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.plot(accuracies)\n","    plt.plot(val_accuracies)\n","    plt.legend(['train_acc', 'val_acc'])\n","\n","(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","print(\"train_images dimentions: \", train_images.ndim)\n","print(\"train_images shape: \", train_images.shape)\n","print(\"train_images type: \", train_images.dtype)\n","X_train = train_images.reshape(60000, 28, 28, 1)\n","X_test = test_images.reshape(10000, 28, 28, 1)\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","Y_train = np_utils.to_categorical(train_labels)\n","Y_test = np_utils.to_categorical(test_labels)\n","myInput = layers.Input(shape=(28,28,1))\n","conv1 = layers.Conv2D(16, 3, activation='relu', padding='same', strides=2)(myInput)\n","conv2 = layers.Conv2D(32, 3, activation='relu', padding='same', strides=2)(conv1)\n","pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n","conv3 = layers.Conv2D(64, 3, activation='relu', padding='same', strides=2)(pool1)\n","flat = layers.Flatten()(conv3)\n","dense1 = layers.Dense(32, activation='relu')(flat)\n","drop = layers.Dropout(0.5)(dense1)\n","dense2 = layers.Dense(16, activation='relu')(drop)\n","out_layer= layers.Dense(10, activation='softmax')(dense2)\n","myModel = Model(myInput, out_layer)\n","myModel.summary()\n","myModel.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n","network_history = myModel.fit(X_train, Y_train, batch_size=128, epochs=50, validation_split=0.2,shuffle=True)\n","plot_history(network_history)\n","test_loss, test_acc = myModel.evaluate(X_test, Y_test)\n","print('test accuracy=',format(test_acc))\n","print('test loss=',format(test_loss))\n"],"execution_count":0,"outputs":[]}]}